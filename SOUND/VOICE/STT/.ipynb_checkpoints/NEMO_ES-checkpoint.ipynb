{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH = 'v1.0.0'\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "try:\n",
    "    from plotly import graph_objects as go\n",
    "except ModuleNotFoundError:\n",
    "    !pip install plotly\n",
    "    from plotly import graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import audio processing library\n",
    "import librosa\n",
    "# We'll use this to listen to audio\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NeMo and it's ASR, NLP and TTS collections\n",
    "import nemo\n",
    "# Import Speech Recognition collection\n",
    "import nemo.collections.asr as nemo_asr\n",
    "# Import Natural Language Processing colleciton\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "# Import Speech Synthesis collection\n",
    "import nemo.collections.tts as nemo_tts\n",
    "# We'll use this to listen to audio\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here is an example of all CTC-based models:\n",
    "nemo_asr.models.EncDecCTCModel.list_available_models()\n",
    "# More ASR Models are available - see: nemo_asr.models.ASRModel.list_available_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech Recognition model - QuartzNet trained on Russian part of MCV 6.0\n",
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"stt_es_quartznet15x5\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download audio sample which we'll try\n",
    "# This is a sample from MCV 6.0 Dev dataset - the model hasn't seen it before\n",
    "# IMPORTANT: The audio must be mono with 16Khz sampling rate\n",
    "Audio_sample = 'SPANISH_PODCAST1126.wav'\n",
    "# load audio signal with librosa\n",
    "signal, sample_rate = librosa.load(Audio_sample, sr=None)\n",
    "# To listen it, click on the play button below\n",
    "IPython.display.Audio(Audio_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_text = quartznet.transcribe([Audio_sample])\n",
    "print(es_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = quartznet.transcribe([Audio_sample], logprobs=True)[0]\n",
    "probs = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax implementation in NumPy\n",
    "def softmax(logits):\n",
    "    e = np.exp(logits - np.max(logits))\n",
    "    return e / e.sum(axis=-1).reshape([logits.shape[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20ms is duration of a timestep at output of the model\n",
    "time_stride = 0.02\n",
    "\n",
    "# get model's alphabet\n",
    "labels = list(quartznet.decoder.vocabulary) + ['blank']\n",
    "labels[0] = 'space'\n",
    "\n",
    "# plot probability distribution over characters for each timestep\n",
    "fig_probs = go.Figure(\n",
    "    go.Heatmap(z=probs.transpose(),\n",
    "               colorscale=[\n",
    "                   [0, 'rgb(30,62,62)'],\n",
    "                   [1, 'rgb(30,255,30)'],\n",
    "               ],\n",
    "               y=labels,\n",
    "               dx=time_stride,\n",
    "               name='Probs',\n",
    "               hovertemplate='Time: %{x:.2f} s<br>Character: %{y}<br>Probability: %{z:.2f}<extra></extra>'),\n",
    "    layout={\n",
    "        'height': 300,\n",
    "        'xaxis': {'title': 'Time, s'},\n",
    "        'yaxis': {'title': 'Characters'},\n",
    "        'title': 'Character Probabilities',\n",
    "        'margin': dict(l=0, r=0, t=40, b=0, pad=0),\n",
    "    }\n",
    ")\n",
    "fig_probs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get timestamps for space symbols\n",
    "spaces = []\n",
    "\n",
    "state = ''\n",
    "idx_state = 0\n",
    "\n",
    "if np.argmax(probs[0]) == 0:\n",
    "    state = 'space'\n",
    "\n",
    "for idx in range(1, probs.shape[0]):\n",
    "    current_char_idx = np.argmax(probs[idx])\n",
    "    if state == 'space' and current_char_idx != 0 and current_char_idx != 28:\n",
    "        spaces.append([idx_state, idx-1])\n",
    "        state = ''\n",
    "    if state == '':\n",
    "        if current_char_idx == 0:\n",
    "            state = 'space'\n",
    "            idx_state = idx\n",
    "\n",
    "if state == 'space':\n",
    "    spaces.append([idx_state, len(pred)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration offset for timestamps: 180 ms\n",
    "offset = -0.18\n",
    "\n",
    "# split the transcript into words\n",
    "words = es_text[0].split()\n",
    "\n",
    "# cut words\n",
    "pos_prev = 0\n",
    "for j, spot in enumerate(spaces):\n",
    "    display(words[j])\n",
    "    pos_end = offset + (spot[0]+spot[1])/2*time_stride\n",
    "    display(Audio(signal[int(pos_prev*sample_rate):int(pos_end*sample_rate)],\n",
    "                 rate=sample_rate))\n",
    "    pos_prev = pos_end\n",
    "\n",
    "display(words[j+1])\n",
    "display(Audio(signal[int(pos_prev*sample_rate):],\n",
    "        rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
